{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-최근접 이웃(KNN) 분류기는 기술적으로 예측을 만들기 위해 모델을 훈련하지 않음. 대신 가장 가까운 k개의 샘플에서 다수으 ㅣ클래스를 그 샘플의 클래스로 예측. 예로, 클래스가 알려지지 않은 한 샘플이 클래스 1인 샘플로 둘러싸여 있다면 그 샘플을 클래스 1로 분류."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15.1 샘플의 최근접 이웃 찾기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "샘플에서 가장 가까운 k개의 샘플(이웃)을 찾음. - 사이킷런의 NearestNeighbors 사용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.03800476, 0.55861082, 1.10378283, 1.18556721],\n",
       "        [0.79566902, 0.32841405, 0.76275827, 1.05393502]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data\n",
    "\n",
    "standardizer =StandardScaler()\n",
    "\n",
    "X_standardized = standardizer.fit_transform(X)\n",
    "\n",
    "\n",
    "# k=2인 최근접 이웃 모델을 만듬.\n",
    "nearest_neighbors = NearestNeighbors(n_neighbors=2).fit(X_standardized)\n",
    "\n",
    "# 새로운 샘플 생성\n",
    "new_observation = [1,1,1,1]\n",
    "\n",
    "# 이 샘플과 가장 가까운 이웃으 ㅣ인덱스와 거리를 찾음.\n",
    "distances, indices = nearest_neighbors.kneighbors([new_observation])\n",
    "\n",
    "# 최근접 이웃을 확인.\n",
    "X_standardized[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.03800476, 0.55861082, 1.10378283, 1.18556721],\n",
       "        [0.79566902, 0.32841405, 0.76275827, 1.05393502]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_standardized[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "해결에서 붓꽃 데이터셋을 사용. 임의의 값으로 새로운 샘플 new_observation를 만들고 데이터셋에서 가장 가까운 두 개의 샘플을 찾음. indices에는 데이터셋에서 가장 가까운 샘플의 위치가 담김. 찾은 샘플의 값을 보려면 X[indices]처럼 사용. 당연히 거리는 일종의 유사도로 생각할 수 있으므로 가장 가까운 두 개의 샘플은 새로운 꽃 샘플과 가장 가까운 두 개의 꽃."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# metric 매개변수를 사용해 거리 측정 방법 지정.\n",
    "# 유클리드 거리 기반으로 가장 가까운 두 개의 최근접 이웃을 찾음.\n",
    "\n",
    "nearestneighbors_euclidean = NearestNeighbors(n_neighbors = 2, metric='euclidean').fit(X_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49140089, 0.74294782]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 거리를 확인. distance 변수는 가장 가까운 두 개의 이웃까지 실제 거릿값.\n",
    "distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kneighbors_grah 메서드를 사용해 샘플의 최근접 이웃을 나타내는 행렬 생성.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 유클리드 거리를 기반으로 각 샘플에 대해(자기 자신을 포함한)\n",
    "# 세 개의 최근접 이웃을 찾음.\n",
    "\n",
    "nearestneighbors_euclidean = NearestNeighbors(n_neighbors= 3, metric='euclidean').fit(X_standardized)\n",
    "\n",
    "# 각 샘플의 (자기 자신을 포함한) 3개의 최근접 이웃을 나타내는 리스트의 리스트\n",
    "nearest_neighbors_with_self = nearestneighbors_euclidean.kneighbors_graph(X_standardized).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_neighbors_with_self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nearest_neighbors_with_self2 = nearestneighbors_euclidean.kneighbors_graph(X_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<150x150 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 450 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_neighbors_with_self2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최근접 이웃 중에서 1로 표시된 자기 자신을 제외시킴.\n",
    "for i, x in enumerate(nearest_neighbors_with_self):\n",
    "    x[i]=0\n",
    "    \n",
    "# 첫 번째 샘플에 대한 두 개의 최근접 이웃을 확인.\n",
    "nearest_neighbors_with_self[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최근접 이웃을 찾거나 거리 기반의 학습 알고리즘을 사용할 때 특성을 같은 스케일을 갖도록 변환하는 것이 중요. 이런 이유는 거리 측정 방법이 모든 특성을 같은  스케일로 다루기 때문. 만약 한 특성이 수 백만 달러 값이고 다른 특성이 퍼센트 값이면 계산된 거리는 전자에 편향. -StandardScaler 표준화로 해결\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[124, 110, 148, 136, 144]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "kneighbors 메서드에서 n_neighbors 매개변수를 다르게 지정. return_distance를 False로 지정하면 최근접 이웃의 인덱스만 반환.\n",
    "\n",
    "new_observation = [1,1,1,1]\n",
    "'''\n",
    "\n",
    "# 이 샘플과 가장 가까운 이웃의 다섯 개의 인덱스를 찾음.\n",
    "indices= nearest_neighbors.kneighbors([new_observation], n_neighbors= 5, return_distance = False)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[6.7, 3.3, 5.7, 2.1],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.7, 3.3, 5.7, 2.5]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "radius_neighbors 메서드는 주어진 반경 내의 이웃을 모두 찾아줌. 반경은 Nearest Neighbors 클래스의 radius에 지정 가능. 이 매개변수의 기본값은 1.0 또한 radius_neighbors 메서드에서도 radius 값을 설정 가능.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([124], dtype=int64)]\n",
      "\n",
      "[[1.03800476 0.55861082 1.10378283 1.18556721]]\n"
     ]
    }
   ],
   "source": [
    "# 반경 0.5안에 있는 모든 샘플의 인덱스를 찾음\n",
    "\n",
    "indices = nearest_neighbors.radius_neighbors([new_observation],radius=0.5, return_distance=False)\n",
    "\n",
    "# 반경 내의 이웃을 확인\n",
    "\n",
    "print(indices)\n",
    "print()\n",
    "\n",
    "print(X_standardized[indices[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kneighbors_graph 메서드와 마찬가지로 radius_neighbors_graph를 사용해 반경 내의 이웃을 나타내는 행렬 생성 가능. 이 메서드도 희소 행렬을 반환하기 때문에 \n",
    "toarray 메서드를 사용해 밀집 배열로 바꿈!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 반경 내의 이웃을 나타내는 리스트의 리스트\n",
    "nearest_neighbors_with_self = nearest_neighbors.radius_neighbors_graph([new_observation], radius=0.5).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 첫 번째 샘플에 대한 반경 내의 이웃을 확인\n",
    "nearest_neighbors_with_self[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_neighbors_with_self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 150)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_neighbors_with_self.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nearest_neighbors_with_self2 = nearest_neighbors.radius_neighbors_graph([new_observation], radius=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x150 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_neighbors_with_self2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 124)\t1.0\n"
     ]
    }
   ],
   "source": [
    "print(nearest_neighbors_with_self2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(nearest_neighbors_with_self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15.2 K-최근접 이웃 분류기 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "클래스를 모르는 샘플이 주어졌을 때 이웃한 샘플의 클래스를 기반으로 이 샘플의 클래스를 예측 -데이터셋이 아주 크지 않으면 KNeighborsClassifier를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X= iris.data\n",
    "Y = iris.target\n",
    "\n",
    "# 표준화 객체를 만듬\n",
    "standardizer = StandardScaler()\n",
    "\n",
    "X_standardized = standardizer.fit_transform(X)\n",
    "\n",
    "# 5개의 이웃을 사용한 KNN 분류기를 훈련\n",
    "knn = KNeighborsClassifier(n_neighbors= 5 , n_jobs =-1).fit(X_standardized,Y)\n",
    "\n",
    "# 두 개의 샘플 새엇ㅇ\n",
    "new_observations = [[0.75,0.75,0.75,0.75], [1,1,1,1]]\n",
    "\n",
    "# 두 샘플의 클래스를 예측\n",
    "knn.predict(new_observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "타깃 클래스를 모르는 샘플x가 주어지면 KNN 알고리즘은 먼저 어떤 거리 측정 방법(예를 들면 유클리드 거리)을 기반으로 가장 가까운 K개의 샘플(x의 이웃)을 찾음. 그다음 이 k개 샘플의 클래스를 기반으로 투표. 가장 많은 표를 얻은 클래스가 x의 예측 클래스가 됌."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0.6, 0.4],\n",
       "       [0. , 0. , 1. ]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사이킷런에서는 predict_proba 메서드를 사용해 이 확률을 출력.\n",
    "# 각 샘플이 세 클래스에 속할 확률을 확인\n",
    "knn.predict_proba(new_observations)\n",
    "\n",
    "# [0,1,2] 로 첫번 째는 1일 확률이 0.6으로 1 두 번째는 2일 확률이 100%이므로 2로 예측."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict(new_observations) #  예측 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNeighborsClassifier에는 중요한 매개변수가 많음. \n",
    "\n",
    "첫째, metric은 사용할 거리 측정 방법을 지정. \n",
    "\n",
    "둘째, n_jobs는 얼마나 ㅁ낳은 컴퓨터 코어를 사용할지 결정.\n",
    "\n",
    "셋째, algorithm 매개변수는 가장 가까운 이웃을 계산하기 위한 방법을 지정\n",
    "\n",
    "넷째 weights를 distance로 지정하면 멀리 떨어진 샘플보다 가까운 이웃의 투표에 가중치가 더 부여."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 회귀 문제에는 KNeighborsRegressor 클래스 사용 사용법은 KNeighborsClassifier와 매우 비슷 보스턴 데이터셋을 사용한 최근접 회귀 모델 훈련\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23089.999999999996"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "X= boston.data\n",
    "Y= boston.target\n",
    "\n",
    "knnRegre = KNeighborsRegressor(n_neighbors= 10)\n",
    "\n",
    "model = knnRegre.fit(X,Y)\n",
    "\n",
    "# 첫 번째 샘플의 타깃값을 예측하고 1000을 곱함\n",
    "model.predict(X[0:1])[0]*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23089.999999999996"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X[0:1])[0]*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24000.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0]*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "KNeighborsClassfier 와 KNeighborsRegressor는 모두 NearestNeighbors 클래스를 상속하기 때문에 kneighbors 메서드를 사용해 최근접 이웃 확인 가능.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23089.999999999996"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "indices = model.kneighbors(X[0:1],return_distance = False)\n",
    "np.mean(Y[indices])*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "arrays used as indices must be of integer (or boolean) type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-46dd94bf9e55>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreturn_distance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "indices = model.kneighbors(X[0:1],return_distance = True)\n",
    "np.mean(Y[indices])*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23089.999999999996"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "distance,indices = model.kneighbors(X[0:1],return_distance = True)\n",
    "np.mean(Y[indices])*1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15.3 최선의 이웃 개수 결정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-최근접 이웃 분류기에서 최선의 K값을 찾음 - GridSearchCV와 같은 모델 선택 기법사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "\n",
    "X= iris.data\n",
    "Y = iris.target\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_std = scaler.fit_transform(X)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)\n",
    "\n",
    "# 파이프라인 생성\n",
    "\n",
    "pipe = Pipeline([(\"standardizer\",scaler),('knn',knn)])\n",
    "\n",
    "# 탐색 영역의 후보를 만듬.\n",
    "search_space = [{'knn__n_neighbors': [1,2,3,4,5,6,7,8,9,10]}]\n",
    "\n",
    "# 그리드 서치를 마늗ㅁ\n",
    "classifier = GridSearchCV(pipe, search_space, cv=5 , verbose=0).fit(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k 값의 크기는 KNN 분류기에 큰 영향을 미침. 편향과 분산 사이에 균형점을 찾아야 하는 머신런이에서 k 값만큼 명확한 경우가 많지 않음. n이 샘플의 개수 일때 k== n이면 편향이 높고 분산이 낮음. k==1 이면 편향이 낮고 분산이 높음. 이 편향-분산 생쇄 오프의 균형을 맞추는 k값을 찾으면 최선의 모델을 만들 수 있음 해결에서 KNN 분류기에 각기 다른 k 값으로 5-폴드 교차검증을 수행하는 GridSearchCV를 사용. 그리드 서치가 완료되면 최선의 모델을 만드는 K를 확인."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.best_estimator_.get_params()[\"knn__n_neighbors\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15.4 반지름 기반의 최근접 이웃 분류기 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "클래스를 모르는 샘플이 주어졌을 때 일정 거리 내의 모든 샘플의 클래스를 기반으로 이 샘플의 클래스를 예측 - RadiusNeighborsClassifier 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X= iris.data\n",
    "Y = iris.target\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_std = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 반지름 이웃 분류기를 훈련\n",
    "\n",
    "rnn= RadiusNeighborsClassifier(radius = .5, n_jobs = -1).fit(X_std,Y)\n",
    "\n",
    "# 샘플 생성\n",
    "new_observations = [[1,1,1,1]]\n",
    "\n",
    "rnn.predict(new_observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN 분류에서 샘플의 클래스는 k개 이웃의 클래스로부터 예측. 반지름 기반(RNN) 분류기는 이보다는 덜 사용되는 분류 방법. 여기서 샘플의 클래스가 주어진 반지름 r 이내에 있는 모든 샘플의 클래스로부터 예측. \n",
    "\n",
    "RadiusNeighborsClassifer는 radius 매개변수로 고정 영역의 반지름을 지정하여 이웃 샘플을 결정. radius를 어떤 값을 지정할 확실한 근거가 있지 않다면 다른 하이퍼파라미터처럼 모델 선택 과정으로 튜닝!\n",
    "\n",
    "두번째로 유용한 매개변수는 outlier_label. 반지름 내에 다른 샘플이 하나도 없는 샘플에 부여할 레이블을 지정. 이 기능을 outlier를 구별하는 데 종종 유용하게 사용. \n",
    "\n",
    "outlier_label 매개변수의 기본값은 None으로 이웃한 샘플을 찾지 못할 경우 예외 발생. 예외를 일으키는 대신 이상치로 표시하려면 일반적으로 클래스 레이블로 사용하지 않는 -1 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 반지름 이웃 분류기를 훈련.\n",
    "\n",
    "rnn = RadiusNeighborsClassifier(radius=.5, outlier_label =1, n_jobs=-1 ).fit(X,Y)\n",
    "rnn.predict([[100,100,100,100]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
